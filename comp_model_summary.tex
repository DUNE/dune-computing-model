\documentclass[pdftex,12pt,letter]{article}
\usepackage[margin=0.75in]{geometry}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{cite}
\usepackage{url}
\usepackage[pdftex,pdfpagelabels,bookmarks,hyperindex,hyperfigures]{hyperref}

\newcommand{\pd}{protoDUNE\xspace}
%\newcommand{\pdsp}{pD/SP\xspace}
\newcommand{\xrd}{XRootD\xspace}
\newcommand{\expname}{\textit{NP04}\xspace}
\newcommand{\eXpname}{\textit{NP02}\xspace}

\title{Brief Summary of the Computing Model for DUNE and \pd}
\date{\today}
\author{M. Potekhin and B. Viren}


\begin{document}
\maketitle

\begin{abstract}
\noindent  This note describes  the salient points of the Computing Model of the DUNE experiment and its the Single-Phase prototype (\pd/\expname).
\end{abstract}

%%%%%%%%%%%%%
\section{Relevant Documents}

The document titled ``Computing Model for the DUNE Experiment'' is kept as entry 914 in FNAL's DocDB system.
It includes the computing model for \pd experiments \eXpname and \expname in Appendix D.

The Computing Model is based on two principal inputs: the \textit{Software and Computing Requirements},
which it includes as Appendix B, and Data Characteristics (Sec.3). The Requirements predate the Computing Model and
are assumed to represent the consensus of what DUNE wants its computing sector to be organized and operated, including
a number of policies. They contain the following categories:
\begin{itemize}
\item Data Requirements
\item Databases
\item Software
\item Distributed Computing
\item Geometry
\item Visualization
\item Networks
\item Cybersecurity
\end{itemize}

\noindent The other component, Data Characteristics, defines the scale and certain technology choices for DUNE computing.
The Data Characterstics are defined by the scale and construction of the detector and its readout chain and digital electronics
as well as the physics processes relevant in its operation. Various relevant parameters are documented in the Computing Model.
The \pd Computing Model is based on same Requirements but has different data characteristics which are also documented.

More recently, a number of supporting documents have been developed such as \cite{docdb1086},\cite{docdb1212},\cite{docdb1811}
which address certain implementation issues for \pd computing.

\section{Scale of Data}
\subsection{DUNE full stream}

Full-stream (FS) data corresponds to reading all data in every ADC channel without
the application of any threshold. The corresponding rate does not depend on the 
activity in the detector or the noise
level of the electronics, although these factors affect the performance of data compression.
It is the most voluminous type of data
that can be generated by the TPC. The parameters which apply to this data are given in
table~\ref{tab:full-stream-parameters}.

\begin{table}[ht!]
	\centering
	\begin{tabular}{| p{3in} | p{1.1in} |}
		\hline

	\textbf{Parameter} & \textbf{Value} \\ \hline
	
	Bytes per sample & 1.5 \\ \hline
	
	DAQ sample rate & 2.0\,Mhz \\ \hline
	
	Channels per APA & 2,560 \\ \hline
	
	Number of APA per detector module & 150 \\ \hline
	
	Number of modules & 4 \\ \hline
	
	Total channels in DUNE & 1,536,000 \\ \hline \hline
	
	Drifts per readout & 2.4 \\ \hline
	
	Drift time & 2.25\,ms \\ \hline

	Total readout window & 5.4\,ms \\ \hline \hline
	
	Beam spill repetition rate & 0.83\,Hz \\ \hline
	
	Annual run time fraction & 0.667 \\ \hline
	\end{tabular}
	\caption{Parameters pertaining to full-stream data rates.}
	\label{tab:full-stream-parameters}
\end{table}
The expected data rates for FS data are given
in table~\ref{tab:full-stream-volume}.
\begin{table}[ht!]
	\centering
	\begin{tabular}{| p{3in} | p{1.1in} |}
		\hline	
	
	\textbf{Parameter} & \textbf{Value} \\ \hline
	Full-stream readout size & 24.9\,GB \\ \hline
	Full-stream 1 year in-spill data volume & 436\,PB \\ \hline
	Full-stream 1 second data volume & 4.6\,TB \\
	Full-stream 1 minute data volume & 276.5\,TB \\	\hline
	Full-stream 1 year data volume & 145.4\,EB \\ \hline
	\end{tabular}
	\caption{Data volumes and rates for full-stream data acquisition.}
	\label{tab:full-stream-volume}
\end{table}

\noindent It is not expected that DUNE will run in the full-stream mode but having these numbers is helpful for reference.


\subsection{DUNE Zero-Suppressed Data}
\label{sec:zs-data}
The current nominal plan for DUNE is to use Zero Suppression. For purposes of this discussion, the nominal
ZS threshold is set to be the ADC counts equivalent to 0.5\,MeV energy deposited
as ionization which is collected by a single wire. It is assumed that the application of zero-suppression at this
threshold completely removes ADC counts due to noise. % although an estimate of data rates due to noise is given.
Estimations of different sources of ZS data are summarized in Table~\ref{tab:zs-volume}. Possible refinments
and variations of zero suppression are not dscussed here for sake of brevity. A related issue
is that of the data format which is not well defined at this point. The numbers presented
in the table are likely to be an overestimation and will be revised at a later date.

	
\begin{table}[ht!]
\centering
\begin{tabular}{| p{1.2in} | p{0.9in} | p{0.75in} | p{0.8in} | p{0.9in} |}		\hline		
Source & Event Rate & Event Size & Data Rate & Volume/year \\ \hline
all $^{39}$Ar & 11.2\,MHz & 150\,B & 1.6 GB/s &  53\,PB \\ \hline
all in-spill & & & & 159\,TB \\ \hline
with-beam-$\nu$ & & & & 79\,GB \\ \hline \hline
cosmic-$\mu$ & 0.259\,Hz &2.5\,MB & 647.4\,kB/s & 20\,TB \\	\hline
beam-$\nu$ & 8770\,year$^{-1}$ & 2.5\,MB & 0.69 kB/s & 22 GB \\ \hline \hline
SNB cand. (ZS) & 12 year$^{-1}$ & 16.7\,GB & 6366\,B/s & 201\,GB \\ \hline
SNB cand. (FS) & 12 year$^{-1}$ & 46.1\,TB & 17.5\,MB/s & 553\,TB \\ \hline
\end{tabular}
\caption{Data rate estimations for ZS data from various sources.
An additional FS data estimation is given for the Supernova Burst (SNB).}
\label{tab:zs-volume}

\end{table}
\noindent In the table above SNB stands for Supernova Burst. This is a very different source of data compared to the beam
and cosmic neutrinos and muons. Such phenomenon (should it occur) will take tens of seconds to complete and will be
characterized by a large number of low-energy neutrino interactions througout the detector volume. Application of
zero suppression may or may not be desirable.


\subsection{DUNE Compressed Data}
Work has been done to estimate the effects of data compression applied post-ZS. There are large uncertainties in these estimates due to
factors related to data formats and eventual noise characteristics in DUNE. As a rule of thumb, compression ratios close to an order of magnitude
can be expected.

\subsection{\pd Data}
The data characteristics in \pd\  -- which is a test-beam experiment located on the surface -- are dramatically different from that of DUNE.
Since zero-suppression in that situation is not well understood it will not be applied to raw data in \pd. Nominal trigger rate is about 50\,Hz
and most of the detector's occupancy will be due to cosmic ray $\mu$'s.


\begin{thebibliography}{1}
\bibitem{docdb914}
{DUNE DocDB 914: \textit{ Computing Model for the DUNE Experiment}}\\
\url{http://docs.dunescience.org:8080/cgi-bin/ShowDocument?docid=914}

\bibitem{docdb1086}
{DUNE DocDB 1086: \textit{ protoDUNE/SP data scenarios with full stream (spreadsheet)}}\\
\url{http://docs.dunescience.org:8080/cgi-bin/ShowDocument?docid=1086}


\bibitem{docdb1212}
{DUNE DocDB 1212: \textit{Design of the Data Management System for the protoDUNE Experiment}}\\
\url{http://docs.dunescience.org:8080/cgi-bin/ShowDocument?docid=1212}


\bibitem{docdb1811}
{DUNE DocDB 1811: \textit{Prompt Processing System Requirements for the Single-Phase protoDUNE}}\\
\url{http://docs.dunescience.org:8080/cgi-bin/ShowDocument?docid=1811}
\end{thebibliography}


\end{document}